{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will load my model and try to lesion a unit in different layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/elaheh_akbari/new/')\n",
    "sys.path.append('/home/elaheh_akbari/new/sdnn-otherrace')\n",
    "sys.path.append('/home/elaheh_akbari/new/sdnn-otherrace/models')\n",
    "sys.path.append('/home/elaheh_akbari/new/sdnn-otherrace/training')\n",
    "sys.path.append('/home/elaheh_akbari/new/sdnn-otherrace/training/utils')\n",
    "from utils.helper import Config\n",
    "from utils.helper import getLayerMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model from raid\n",
    "filename = '../../../../raid/elaheh_akbari/face_otherrace_white_asian/checkpoints/vgg/face_otherrace_white_asian/epoch_261.pth.tar'\n",
    "# checkpoint = torch.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: /raid/shared/datasets/visoin/data_face_white/data_facecar_na/train\n",
      "dir: /raid/shared/datasets/visoin/data_face_asian/data_AFD_matched/train\n",
      "3308\n",
      "Restored from: ../../../../raid/elaheh_akbari/face_otherrace_white_asian/checkpoints/vgg/face_otherrace_white_asian/epoch_261.pth.tar\n"
     ]
    }
   ],
   "source": [
    "config_file = './configs/vgg/face_dual_whitasia.yaml'\n",
    "config = Config(config_file=config_file)\n",
    "model, ckpt_data = config.get_model(pretrained=True, ngpus=1, dataParallel=True, epoch=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['batch_size', 'learning_rate', 'momentum', 'weight_decay', 'walltime', 'epoch', 'keep_epochs', 'state_dict', 'optimizer', 'scheduler'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=3308, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ckpt_data['state_dict']\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerMap = getLayerMapping(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramWeightAndBiasGroupIndex = 0  # decide about the layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeightandBias(model, layerMap, paramWeightAndBiasGroupIndex):\n",
    "    key = 'ParamWeightAndBiasGroupIndex2ParamWeightAndBiasIndexPair'\n",
    "    weightAndBiasIndexPair = layerMap[key][paramWeightAndBiasGroupIndex]\n",
    "    weight_index, bias_index = weightAndBiasIndexPair\n",
    "    tempParameters = list(model.parameters())\n",
    "    if weight_index is not None:\n",
    "        weight = tempParameters[weight_index]\n",
    "    bias=None\n",
    "    if bias_index is not None:\n",
    "        bias = tempParameters[bias_index]\n",
    "    return weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight , bias = getWeightandBias(model, layerMap, paramWeightAndBiasGroupIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the weight is: 64\n",
      "The length of the bias is: 64\n"
     ]
    }
   ],
   "source": [
    "print(f'The length of the weight is: {len(weight)}')\n",
    "print(f'The length of the bias is: {len(bias)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {'W':{}, 'b':{}}\n",
    "for unit in range(len(weight)):\n",
    "        cache['W'][unit] = weight[unit].detach().cpu().numpy()\n",
    "        if bias is not None:\n",
    "            cache['b'][unit] = bias[unit].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-7.36340731e-02, -2.30240393e-02, -9.43707377e-02],\n",
       "        [-9.67890248e-02, -1.52930245e-01, -1.95417032e-02],\n",
       "        [-5.13911359e-02, -1.78879574e-01, -8.80359039e-02]],\n",
       "\n",
       "       [[-7.06956610e-02,  2.28542387e-02, -1.05799204e-02],\n",
       "        [-1.42074535e-02, -7.92321712e-02, -9.52006802e-02],\n",
       "        [-6.23369701e-02,  1.71015708e-04, -4.02077213e-02]],\n",
       "\n",
       "       [[-1.78099163e-02, -3.52552310e-02,  8.13705176e-02],\n",
       "        [-7.99140781e-02, -9.80853364e-02,  6.72545433e-02],\n",
       "        [ 2.57421937e-02, -7.37561360e-02, -1.28399171e-02]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['W'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e44c1b3031cbfcaa4ec193c7a7114f61e8449c1832cca6a40e7774c05b50837f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
