dir: /raid/shared/datasets/visoin/data_face_white/data_facecar_na/train
dir: /raid/shared/datasets/visoin/data_face_asian/data_AFD_matched/train
3308
Restored from: ../../../../../raid/elaheh_akbari/face_otherrace_white_asian/checkpoints/vgg/face_otherrace_white_asian/epoch_261.pth.tar
dir: /raid/shared/datasets/visoin/data_face_white/data_facecar_na/train
dir: /raid/shared/datasets/visoin/data_face_asian/data_AFD_matched/train

read_seed: 0

Frequency of classes:
[[1654 1655 1656 ... 3305 3306 3307]
 [  58   58   58 ...   58   58   58]]

False

---CONFIGURATION---
------------------------
config.name                   : face_otherrace_white_asian
config.description            : Training VGG on VGGFace using white and asian dataset
config.model_type             : VGG16
config.num_classes            : 3308
config.split                  : False
config.batch_size             : 128
config.optimizer              : sgd
config.momentum               : 0.9
config.learning_rate          : 0.001
config.weight_decay           : 0.0001
config.data_dir               : [
                              : /raid/shared/datasets/visoin/data_face_white/data_facecar_na
                              : /raid/shared/datasets/visoin/data_face_asian/data_AFD_matched
                              : ]
config.checkpoints_dir        : /raid/elaheh_akbari/face_otherrace_white_asian/checkpoints/vgg/face_otherrace_white_asian
config.log_dir                : /raid/elaheh_akbari/face_otherrace_white_asian/runs/vgg/face_otherrace_white_asian
config.max_train_samples      : {'data_facecar_na': 58, 'data_AFD_matched': 58}
config.max_valid_samples      : {'data_facecar_na': 5, 'data_AFD_matched': 5}
------------------------


--------MODEL-----------
------------------------
DataParallel(
  (module): VGG(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (6): ReLU(inplace=True)
      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (8): ReLU(inplace=True)
      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (11): ReLU(inplace=True)
      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (13): ReLU(inplace=True)
      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (15): ReLU(inplace=True)
      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (18): ReLU(inplace=True)
      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (20): ReLU(inplace=True)
      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (22): ReLU(inplace=True)
      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (25): ReLU(inplace=True)
      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (27): ReLU(inplace=True)
      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (29): ReLU(inplace=True)
      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (classifier): Sequential(
      (0): Linear(in_features=25088, out_features=4096, bias=True)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=True)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=3308, bias=True)
    )
  )
)
------------------------


---------------FLAGS------------------
--------------------------------------
config_file                             : ./configs/vgg/face_dual_whitasia.yaml
param_group_index                       : 0
greedy_p                                : 0.25
group_p                                 : 0.016
shuffle                                 : False
random                                  : False
ngpus                                   : 1
batch_size                              : 128
max_batches                             : 50
workers                                 : 1
sort_task_index                         : 1
nonsort_task_index                      : 0
restore_epoch                           : -1
lesion_name                             : layer0newenv00
read_suffix                             : 
lesions_dir                             : ./lesions/
evaluate                                : False
iterator_seed                           : selection
read_seed                               : 0
maxout                                  : True
randomize_classes                       : False
randomize_classes_seed                  : 1
write_predictions                       : False
subgroups_file                          : None
--------------------------------------

----------NUMBER OF SAMPLES-----------
--------------------------------------
validator.name                          : sort_task_train_data

Samples by torch.dataset:
-------------------------
num_steps                               : 750
~num_samples                            : 96000

Samples by Configuration:
-------------------------
data_AFD_matched                        : 0
--num_classes                           : 1654

data_facecar_na                         : 95932
--num_classes                           : 1654

total                                   : 95932
--------------------------------------

-------SAVE FILE--------
------------------------

Results being saved to: ./lesions/vgg/face_otherrace_white_asian/LESION_NAME_layer0newenv00/lesion.jsonl


Record Files:

Selections Records: ./lesions/vgg/face_otherrace_white_asian/LESION_NAME_layer0newenv00/selections_records/SORTEDBY_data_facecar_na/PARAM_GROUP_INDEX_0

Progress Records: ./lesions/vgg/face_otherrace_white_asian/LESION_NAME_layer0newenv00/progress_records/SORTEDBY_data_facecar_na/PARAM_GROUP_INDEX_0

Creating new jsonlines file...

Starting Greedy Layer Lesion on Train Data
------------------------------------------

Using Methods:
greedy_p =  0.25
Approximation Method: None

validator.name                          : sort_task_train_data
index                                   : 0
layer                                   : 0
layerType                               : <class 'torch.nn.modules.conv.Conv2d'>
num_units                               : 64

Getting Base Performance...
(base loss, base accuracy, seed)                : (0.488, 90.422, 295)


---------------------------------------------------------------------
/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
progress_filename: ./lesions/vgg/face_otherrace_white_asian/LESION_NAME_layer0newenv00/progress_records/SORTEDBY_data_facecar_na/PARAM_GROUP_INDEX_0/progress_record_ITER_0.npz

selected_units: []

selected_losses: []

Losses conditioned on 0 selected units w/ seed value=295
---------------------------------------------------------------------
(loss, accuracy) @unit 0        : (0.486, 90.297)
(loss, accuracy) @unit 1        : (0.494, 90.344)
(loss, accuracy) @unit 2        : (0.502, 90.062)

(loss, accuracy) @unit 3        : (0.493, 90.500)

(loss, accuracy) @unit 4        : (0.488, 90.422)

(loss, accuracy) @unit 5        : (0.519, 90.000)

(loss, accuracy) @unit 6        : (0.537, 88.703)

(loss, accuracy) @unit 7        : (0.489, 90.312)

(loss, accuracy) @unit 8        : (0.498, 89.969)

(loss, accuracy) @unit 9        : (0.488, 90.422)

(loss, accuracy) @unit 10       : (0.488, 90.438)

(loss, accuracy) @unit 11       : (0.488, 90.406)

(loss, accuracy) @unit 12       : (0.488, 90.391)

(loss, accuracy) @unit 13       : (0.473, 90.281)

(loss, accuracy) @unit 14       : (0.468, 89.875)

(loss, accuracy) @unit 15       : (0.490, 90.406)

(loss, accuracy) @unit 16       : (0.487, 90.281)

(loss, accuracy) @unit 17       : (0.486, 90.062)

(loss, accuracy) @unit 18       : (0.489, 90.375)

(loss, accuracy) @unit 19       : (0.487, 90.391)

(loss, accuracy) @unit 20       : (0.488, 90.422)

(loss, accuracy) @unit 21       : (0.509, 89.922)

(loss, accuracy) @unit 22       : (0.487, 90.266)

(loss, accuracy) @unit 23       : (0.490, 90.406)

(loss, accuracy) @unit 24       : (0.504, 89.891)

(loss, accuracy) @unit 25       : (0.487, 90.391)

(loss, accuracy) @unit 26       : (0.488, 90.422)

(loss, accuracy) @unit 27       : (0.489, 90.344)

(loss, accuracy) @unit 28       : (0.482, 90.328)

(loss, accuracy) @unit 29       : (0.504, 90.016)

(loss, accuracy) @unit 30       : (0.533, 89.219)

(loss, accuracy) @unit 31       : (0.479, 90.312)

(loss, accuracy) @unit 32       : (0.487, 90.344)

(loss, accuracy) @unit 33       : (0.491, 90.344)

(loss, accuracy) @unit 34       : (0.484, 90.375)

(loss, accuracy) @unit 35       : (0.543, 89.328)

(loss, accuracy) @unit 36       : (0.488, 90.344)

(loss, accuracy) @unit 37       : (0.490, 90.328)

(loss, accuracy) @unit 38       : (0.488, 90.422)

(loss, accuracy) @unit 39       : (0.489, 90.438)

(loss, accuracy) @unit 40       : (0.488, 90.359)

(loss, accuracy) @unit 41       : (0.490, 90.406)

(loss, accuracy) @unit 42       : (0.492, 90.359)

(loss, accuracy) @unit 43       : (0.467, 89.938)

(loss, accuracy) @unit 44       : (0.488, 90.422)

(loss, accuracy) @unit 45       : (0.488, 90.438)

(loss, accuracy) @unit 46       : (0.492, 90.359)

(loss, accuracy) @unit 47       : (0.489, 90.375)

(loss, accuracy) @unit 48       : (0.488, 90.359)

(loss, accuracy) @unit 49       : (0.488, 90.422)

(loss, accuracy) @unit 50       : (0.489, 90.375)

(loss, accuracy) @unit 51       : (0.488, 90.391)

(loss, accuracy) @unit 52       : (0.486, 90.344)

(loss, accuracy) @unit 53       : (0.488, 90.391)

(loss, accuracy) @unit 54       : (0.491, 90.297)

(loss, accuracy) @unit 55       : (0.491, 90.297)

(loss, accuracy) @unit 56       : (0.490, 90.375)

(loss, accuracy) @unit 57       : (0.484, 90.297)

(loss, accuracy) @unit 58       : (0.503, 90.094)

(loss, accuracy) @unit 59       : (0.492, 90.453)

(loss, accuracy) @unit 60       : (0.494, 90.203)

(loss, accuracy) @unit 61       : (0.488, 90.422)

(loss, accuracy) @unit 62       : (0.482, 90.297)

(loss, accuracy) @unit 63       : (0.488, 90.422)

Unit == None
\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
--------------------------------------------------------------------

conclusion_count: 1
selection_made: True
Getting Base Performance...
(base loss, base accuracy, seed)                : (0.488, 90.422, 311)


---------------------------------------------------------------------
/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
progress_filename: ./lesions/vgg/face_otherrace_white_asian/LESION_NAME_layer0newenv00/progress_records/SORTEDBY_data_facecar_na/PARAM_GROUP_INDEX_0/progress_record_ITER_1.npz

selected_units: [35]

selected_losses: [0.54308909]

Losses conditioned on 1 selected units w/ seed value=311
---------------------------------------------------------------------
(loss, accuracy) @unit 0        : (0.541, 89.359)
(loss, accuracy) @unit 1        : (0.558, 89.016)
(loss, accuracy) @unit 2        : (0.578, 88.516)

(loss, accuracy) @unit 3        : (0.549, 89.234)

(loss, accuracy) @unit 4        : (0.543, 89.344)

(loss, accuracy) @unit 5        : (0.614, 88.125)

(loss, accuracy) @unit 6        : (0.551, 88.391)

(loss, accuracy) @unit 7        : (0.545, 89.359)

(loss, accuracy) @unit 8        : (0.551, 89.141)

(loss, accuracy) @unit 9        : (0.543, 89.281)

(loss, accuracy) @unit 10       : (0.543, 89.328)

(loss, accuracy) @unit 11       : (0.543, 89.297)

(loss, accuracy) @unit 12       : (0.544, 89.344)

(loss, accuracy) @unit 13       : (0.520, 89.234)

(loss, accuracy) @unit 14       : (0.519, 88.672)

(loss, accuracy) @unit 15       : (0.546, 89.375)

(loss, accuracy) @unit 16       : (0.542, 89.312)

(loss, accuracy) @unit 17       : (0.516, 89.750)

(loss, accuracy) @unit 18       : (0.543, 89.297)

(loss, accuracy) @unit 19       : (0.541, 89.203)

(loss, accuracy) @unit 20       : (0.543, 89.312)

(loss, accuracy) @unit 21       : (0.550, 89.359)

(loss, accuracy) @unit 22       : (0.542, 89.266)

(loss, accuracy) @unit 23       : (0.536, 89.594)

(loss, accuracy) @unit 24       : (0.593, 88.234)

(loss, accuracy) @unit 25       : (0.540, 89.359)

(loss, accuracy) @unit 26       : (0.543, 89.328)

(loss, accuracy) @unit 27       : (0.544, 89.312)

(loss, accuracy) @unit 28       : (0.538, 89.328)

(loss, accuracy) @unit 29       : (0.575, 88.781)

(loss, accuracy) @unit 30       : (0.553, 88.938)

(loss, accuracy) @unit 31       : (0.534, 89.219)

(loss, accuracy) @unit 32       : (0.542, 89.328)

(loss, accuracy) @unit 33       : (0.533, 89.828)

(loss, accuracy) @unit 34       : (0.538, 89.328)

(loss, accuracy) @unit 36       : (0.544, 89.266)

(loss, accuracy) @unit 37       : (0.555, 89.203)

(loss, accuracy) @unit 38       : (0.543, 89.297)

(loss, accuracy) @unit 39       : (0.544, 89.359)

(loss, accuracy) @unit 40       : (0.543, 89.297)

(loss, accuracy) @unit 41       : (0.546, 89.312)

(loss, accuracy) @unit 42       : (0.553, 89.125)

(loss, accuracy) @unit 43       : (0.539, 88.266)

(loss, accuracy) @unit 44       : (0.545, 89.281)

(loss, accuracy) @unit 45       : (0.543, 89.344)

(loss, accuracy) @unit 46       : (0.519, 89.844)

(loss, accuracy) @unit 47       : (0.548, 89.141)

(loss, accuracy) @unit 48       : (0.542, 89.406)

(loss, accuracy) @unit 49       : (0.543, 89.312)

(loss, accuracy) @unit 50       : (0.546, 89.266)

(loss, accuracy) @unit 51       : (0.543, 89.328)

(loss, accuracy) @unit 52       : (0.538, 89.328)

(loss, accuracy) @unit 53       : (0.544, 89.359)

(loss, accuracy) @unit 54       : (0.530, 89.766)

(loss, accuracy) @unit 55       : (0.566, 88.672)

(loss, accuracy) @unit 56       : (0.545, 89.266)

(loss, accuracy) @unit 57       : (0.542, 89.312)

(loss, accuracy) @unit 58       : (0.591, 88.375)

(loss, accuracy) @unit 59       : (0.554, 89.266)

(loss, accuracy) @unit 60       : (0.539, 89.344)

(loss, accuracy) @unit 61       : (0.543, 89.328)

(loss, accuracy) @unit 62       : (0.558, 88.594)

(loss, accuracy) @unit 63       : (0.543, 89.344)

Unit == None
\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
--------------------------------------------------------------------

conclusion_count: 1
selection_made: True
Getting Base Performance...
(base loss, base accuracy, seed)                : (0.488, 90.422, 17)


---------------------------------------------------------------------
/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
progress_filename: ./lesions/vgg/face_otherrace_white_asian/LESION_NAME_layer0newenv00/progress_records/SORTEDBY_data_facecar_na/PARAM_GROUP_INDEX_0/progress_record_ITER_2.npz

selected_units: [35  5]

selected_losses: [0.54308909 0.61377466]

Losses conditioned on 2 selected units w/ seed value=17
---------------------------------------------------------------------
(loss, accuracy) @unit 0        : (0.612, 87.969)
(loss, accuracy) @unit 1        : (0.633, 87.547)
(loss, accuracy) @unit 2        : (0.678, 86.531)

(loss, accuracy) @unit 3        : (0.617, 88.047)

(loss, accuracy) @unit 4        : (0.614, 88.125)

(loss, accuracy) @unit 6        : (0.551, 88.297)

(loss, accuracy) @unit 7        : (0.616, 88.078)

(loss, accuracy) @unit 8        : (0.670, 86.906)

(loss, accuracy) @unit 9        : (0.614, 88.125)

(loss, accuracy) @unit 10       : (0.614, 88.109)

(loss, accuracy) @unit 11       : (0.614, 88.125)

(loss, accuracy) @unit 12       : (0.615, 88.000)

(loss, accuracy) @unit 13       : (0.596, 87.781)

(loss, accuracy) @unit 14       : (0.580, 87.656)

(loss, accuracy) @unit 15       : (0.617, 87.969)

(loss, accuracy) @unit 16       : (0.612, 88.109)

(loss, accuracy) @unit 17       : (0.555, 88.781)

(loss, accuracy) @unit 18       : (0.615, 88.125)

(loss, accuracy) @unit 19       : (0.607, 87.922)

(loss, accuracy) @unit 20       : (0.614, 88.062)

(loss, accuracy) @unit 21       : (0.659, 87.328)

(loss, accuracy) @unit 22       : (0.605, 88.062)

(loss, accuracy) @unit 23       : (0.605, 88.281)

(loss, accuracy) @unit 24       : (0.726, 85.625)

(loss, accuracy) @unit 25       : (0.612, 88.047)

(loss, accuracy) @unit 26       : (0.614, 88.125)

(loss, accuracy) @unit 27       : (0.616, 88.094)

(loss, accuracy) @unit 28       : (0.606, 88.031)

(loss, accuracy) @unit 29       : (0.702, 86.531)

(loss, accuracy) @unit 30       : (0.558, 88.922)

(loss, accuracy) @unit 31       : (0.602, 88.078)

(loss, accuracy) @unit 32       : (0.611, 88.141)

(loss, accuracy) @unit 33       : (0.584, 88.672)

(loss, accuracy) @unit 34       : (0.608, 88.094)

(loss, accuracy) @unit 36       : (0.614, 88.000)

(loss, accuracy) @unit 37       : (0.623, 87.984)

(loss, accuracy) @unit 38       : (0.614, 88.141)

(loss, accuracy) @unit 39       : (0.614, 87.969)

(loss, accuracy) @unit 40       : (0.613, 88.031)

(loss, accuracy) @unit 41       : (0.616, 87.969)

(loss, accuracy) @unit 42       : (0.628, 87.875)

(loss, accuracy) @unit 43       : (0.629, 86.562)

(loss, accuracy) @unit 44       : (0.614, 88.125)

(loss, accuracy) @unit 45       : (0.614, 88.094)

(loss, accuracy) @unit 46       : (0.586, 88.734)

(loss, accuracy) @unit 47       : (0.621, 87.906)

(loss, accuracy) @unit 48       : (0.609, 88.031)

(loss, accuracy) @unit 49       : (0.614, 88.109)

(loss, accuracy) @unit 50       : (0.618, 88.016)

(loss, accuracy) @unit 51       : (0.614, 88.125)

(loss, accuracy) @unit 52       : (0.604, 88.094)

(loss, accuracy) @unit 53       : (0.617, 88.078)

(loss, accuracy) @unit 54       : (0.581, 88.594)

(loss, accuracy) @unit 55       : (0.640, 87.484)

(loss, accuracy) @unit 56       : (0.615, 88.094)

(loss, accuracy) @unit 57       : (0.614, 87.969)

(loss, accuracy) @unit 58       : (0.732, 85.797)

(loss, accuracy) @unit 59       : (0.624, 87.844)

(loss, accuracy) @unit 60       : (0.628, 87.812)

(loss, accuracy) @unit 61       : (0.614, 88.125)

(loss, accuracy) @unit 62       : (0.658, 86.609)

(loss, accuracy) @unit 63       : (0.614, 88.125)

Unit == None
\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
--------------------------------------------------------------------

conclusion_count: 1

selection_made: True
Getting Base Performance...
(base loss, base accuracy, seed)                : (0.488, 90.422, 826)


---------------------------------------------------------------------
/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
progress_filename: ./lesions/vgg/face_otherrace_white_asian/LESION_NAME_layer0newenv00/progress_records/SORTEDBY_data_facecar_na/PARAM_GROUP_INDEX_0/progress_record_ITER_3.npz

selected_units: [35  5 58]

selected_losses: [0.54308909 0.61377466 0.73170793]

Losses conditioned on 3 selected units w/ seed value=826
---------------------------------------------------------------------
(loss, accuracy) @unit 0        : (0.731, 85.766)
(loss, accuracy) @unit 1        : (0.761, 85.062)
(loss, accuracy) @unit 2        : (0.843, 83.266)

(loss, accuracy) @unit 3        : (0.737, 85.828)

(loss, accuracy) @unit 4        : (0.732, 85.891)

(loss, accuracy) @unit 6        : (0.594, 87.531)

(loss, accuracy) @unit 7        : (0.736, 85.812)

(loss, accuracy) @unit 8        : (0.842, 83.484)

